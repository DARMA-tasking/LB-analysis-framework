To start, we place ourselves in the idealize case where all objects
$O_i\in\mathbf{P}$ have the same load $load(O_i)=\ell$.
Although it is safe to assume that this ideal case will very seldom,
if ever, be encountered in any real case, it is important that any
proposed load-balancing algorithm be able to perform optimally in this
case.

Evidently, if $\vert\mathbf{P}\vert$ divides $\vert\mathbf{O}\vert$,
then any  equi-distribution is optimal and is obtained by assigning
exactly $\tfrac{\vert\mathbf{O}\vert}{\vert\mathbf{P}\vert}$ object(s)
to each processor in $\mathbf{P}$.
We thus present below the respective results of the
Grapevine algorithm with both original criterion \texttt{6} (left) and
our modified criterion \texttt{6'}, for a case where
$\mathbf{P}=10^2$, $\mathbf{O}=10^4$, $i=k=f=4$, $t=1.0$, and where
the unit load is chosen to be $\ell=1$:
\begin{center}
\begin{tabular}{lcrr}
\hline
statistic & iteration & criterion \texttt{6} & criterion \texttt{6'} \\
\hline\hline
\multirow{2}{*}{$\min{\mathcal{L}}$}
&$0$ &$80$   &$80$   \\ &$4$ &$99$    &$100$ \\\hline
\multirow{2}{*}{$\max{\mathcal{L}}$}
&$0$ &$123$  &$123$  \\ &$4$ &$116$   &$100$ \\\hline
\multirow{2}{*}{$\sigma_{\mathcal{L}}$}
&$0$ &$9.18$ &$9.18$ \\ &$4$ &$2.34$  &$0.00$ \\\hline
\multirow{2}{*}{$\mathcal{I}_\mathcal{L}$}
&$0$ &$0.23$ &$0.23$ \\ &$4$ &$0.16$  &$0$ \\\hline
\end{tabular}
\end{center}
The above results demonstrate that even with small numbers of fanout,
gossiping round, and iterations, our alternatre approach converges to
the optimal solution whereas the original one does not, even with this
simple academic case. This first baseline case is thus discriminating
enough to be retained.

In order to extend the set of baseline cases, we now consider a
slightly broader class of distributions, where all 
objects still have equal load $\ell$, but where it is no longer
required that $\vert\mathbf{P}\vert$ divide $\vert\mathbf{O}\vert$.
In this context, denoting
$q=\lfloor\sfrac{\vert\mathbf{O}\vert}{\vert\mathbf{P}\vert}\rfloor$
and $r=\vert\mathbf{O}\vert\bmod\vert\mathbf{P}\vert$, consider a
distribution of $q$ objects on $\vert\mathbf{P}\vert-r$ processors 
($0\le{r}<\vert\mathbf{P}\vert$ by definition of the Euclidean
division) and $q+1$ objects on the remaining $r$
processors. All objects are indeed assigned because
$r(q+1)+(\vert\mathbf{P}\vert-r)q=r+q\vert\mathbf{P}\vert=\vert\mathbf{O}\vert$.
We thus have, if $r\neq0$ (i.e., in the non-divisible case):
\begin{align*}
\min{\mathcal{L}}
&= q\ell,\\
\max{\mathcal{L}}
&= (q+1)\ell,\\
\overline{\mathcal{L}}
&= \frac{\vert\mathbf{O}\vert}{\vert\mathbf{P}\vert}\ell,
\end{align*}
wherefrom we find that
\[
\mathcal{I}_{\mathcal{L}} =
\frac{q+1}
{\sfrac{\vert\mathbf{O}\vert}{\vert\mathbf{P}\vert}} - 1
=
\frac{q\vert\mathbf{P}\vert + \vert\mathbf{P}\vert
- \vert\mathbf{O}\vert}{\vert\mathbf{O}\vert}
=
\frac{\vert\mathbf{P}\vert - r}{\vert\mathbf{O}\vert}
> 0.
\]
We note that the case where $r=0$, we have instead
\[
\mathcal{I}_{\mathcal{L}} =
\frac{q}
{\sfrac{\vert\mathbf{O}\vert}{\vert\mathbf{P}\vert}} - 1
=
\frac{q\vert\mathbf{P}\vert - \vert\mathbf{O}\vert}
{\vert\mathbf{O}\vert}
= 0,
\]
which amounts to the previously discussed distribution where
$\vert\mathbf{P}\vert$ divides $\vert\mathbf{O}\vert$, that we already
proved to be optimal.

Furthermore, as soon $r\neq0$, any other distribution which
would assign more than $q+1$ objects to at least one processor would
have a larger imbalance, because the denominator
$\overline{\mathcal{L}}$ in $\mathcal{I}_{\mathcal{L}}$ is fixed.
Therefore, a distribution $\mathcal{L}$ of
$\vert\mathbf{O}\vert$ objects with identical load $\ell$ across
$\vert\mathbf{P}\vert$ processors is optimal if and only if it can be
written (with no loss of generality, up to a re-indexing of
processors) as follows:
\[
\mathcal{L}=
(q+1)\ell \sum_{i=1}^{r}\delta_i
+ q\ell\!\sum_{i=r+1}^{\vert{\mathbf{P}}\vert}\delta_i.
\]
Because $\delta_i\delta_j=\delta_i$ if $i=j$, and $0$ otherwise, we have
\[
\mathcal{L}^2=
(q+1)^2\ell^2\sum_{i=1}^{r}\delta_i
+ q^2\ell^2\sum_{i=r+1}^{\vert{\mathbf{P}}\vert}\delta_i
\]
as all cross-products vanish, and thus
\[
\overline{\mathcal{L}^2}=
(q+1)^2\ell^2\sum_{i=1}^{r}\overline{\delta_i}
+ q^2\ell^2\sum_{i=r+1}^{\vert{\mathbf{P}}\vert}\overline{\delta_i}
= (q+1)^2\ell^2\frac{r}{\vert{\mathbf{P}}\vert}
+ q^2\ell^2\frac{\vert{\mathbf{P}}\vert-r}{\vert{\mathbf{P}}\vert}
= \frac{\ell^2}{\vert{\mathbf{P}}\vert}
(r + 2qr + q^2\vert{\mathbf{P}}\vert).
\]
This allows us to compute the variance of $\mathcal{L}$, as follows:
\begin{align*}
\sigma_{\mathcal{L}}^2
&= \overline{\mathcal{L}^2} - (\overline{\mathcal{L}})^2\\
&= \frac{\ell^2}{\vert{\mathbf{P}}\vert}
\big(r + 2qr + q^2\vert{\mathbf{P}}\vert\big)
- \frac{\vert\mathbf{O}\vert^2}{\vert\mathbf{P}\vert^2}\ell^2\\
&= \frac{\ell^2}{\vert{\mathbf{P}}\vert^2}
\left[r\vert{\mathbf{P}}\vert + 2qr\vert{\mathbf{P}}\vert
+ q^2\vert{\mathbf{P}}\vert^2 
- (q\vert{\mathbf{P}}\vert+r)^2\right]\\
&= \frac{\ell^2 r(\vert{\mathbf{P}}\vert - r)}
{\vert{\mathbf{P}}\vert^2}.
\end{align*}
We note that in the particular case where $r=0$, the latter result
indeed yields the null variance.
More generally, this result is not only useful in the case where
all objects have identical load~$\ell$: rather, the statistics that we
have derived above may also be used as approximations of the expected
load-balancing results when the objects are of relatively homogenous
sizes.
