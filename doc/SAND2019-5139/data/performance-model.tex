To further elucidate the theoretical tradeoff between utilizing more iterations
($i$) or gossiping rounds ($k$), we build a performance model for the load
balancing algorithm to model the computational complexity.

The implementation of the \textsf{Grapevine} algorithm relies on having
efficient termination detection, an extensively well-researched distributed
computing problem. A distributed computation is globally terminated if every
process is locally terminated and there is no message in transit between any
processes. Termination detection is an important distributed problem,
on which many non-bulk-synchronous algorithms rely in order to
correctly sequence operations across complex dynamic communication
patterns.
In \textsf{Grapevine}, it is used to determine when gossiping is
finished and when all load transfers have occurred.

Chandy and Misra~\cite{chandy1986processes} prove the lower and upper bounds on
the control message complexity $T_m$ for any termination detection algorithm,
where $\vert\mathbf{M}\vert$ is the total number of messages in an underlying computation and $\vert\mathbf{P}\vert$
is the number of processors.
\[
T_m = O(\vert\mathbf{M}\vert) = \Omega(\vert\mathbf{P}\vert).
\]

Intuitively, the worst-case bound occurs when for every computation message, the
termination detection algorithm is activated. The ``dynamic'' Dijkstra-Scholten
termination algorithm~\cite{dijkstra1980termination} for diffusing computations
utilizes an engagement tree to obtain this bound tightly but never performs
better---even in ``best'' case situations--- than $\Theta(\vert\mathbf{M}\vert)$. For distributed
applications in less tightly coupled applications or cases with partial
processor engagement in the computation, this algorithm tends to perform well in
practice. Thus, even the best case time complexity $T_c$ for the
Dijkstra-Scholten algorithms is very costly (and is notably not scalable with
respect to $\vert\mathbf{P}\vert$):
\[
T_c = \Omega(\vert\mathbf{P}\vert).
\]

In contrast, in tightly-coupled cases when all processors are engaged in the
computation, as in the \textsf{Grapevine} algorithm, $O(\vert\mathbf{M}\vert)$ is overly costly to
assume in practice. Thus, the 4-counter, wave-based termination algorithm is
often applied in these contexts that reaches a message complexity lower bound of
$2\times \vert\mathbf{P}\vert$ in the best case scenario, but costs $O(\vert\mathbf{M}\vert\times \vert\mathbf{P}\vert)$ in the worst
case. However, without arbitrary delays in the computation across all the
processors, a small factor on top of $2\times \vert\mathbf{P}\vert$ is a highly probable outcome
when utilizing termination to sequence phases in \textsf{Grapevine}. With the
message complexity, we can also bound the time complexity for the 4-counter
termination detection algorithm:
\[
T_c = O(\vert\mathbf{M}\vert\times \log(\vert\mathbf{P}\vert)) = \Omega(2\times \log(\vert\mathbf{P}\vert)).
\]

With $T_c$ in place, we bound the time complexity of the \textsf{Grapevine}
algorithm, for a single iteration, denoted as $G_c$. We assume that $f$, the
fanout during the gossip phase, is a small constant, where $f \ll P$.
\[
G_c = O(f\times \mathrm{min}(k, \log_f(\vert\mathbf{P}\vert)) + \vert\mathbf{O}\vert + 2 \times T_c)
\]
where:
\begin{align*}
 k          & = \mathrm{the\ number\ of\ gossiping\ rounds} \\
 f          & = \mathrm{the\ fanout\ during\ gossip\ where} f \ll \vert\mathbf{P}\vert \\
 \mathbf{P} & = \mathrm{the\ set\ of\ processors} \\
 \mathbf{O} & = \mathrm{the\ set\ of\ objects\ where\ } \vert\mathbf{O}\vert = O(\vert\mathbf{P}\vert).
\end{align*}
% k * f
% f > 1 and f << P
% O == Theta(x * P)

% log(P) + (f * g)
% pick one (O(1))
%

The \textsf{Grapevine} algorithm, as originally described, can cost
$\vert\mathbf{O}\vert$ in the worst case during the transfer phase. This is
observed when the load~$L_i$ of a single processor is composed of all objects
$\mathbf{O}$ in the system. The original algorithm contains a while loop that
will attempt to reassign all these objects living a single processor during a
single iteration of the \textsf{Grapevine} algorithm. For the
\textsf{Grapevine} algorithm to be scalable in the worst case, we must
bound the number of possible transfers at each iteration by
$\log(\vert\mathbf{P}\vert)$. 
